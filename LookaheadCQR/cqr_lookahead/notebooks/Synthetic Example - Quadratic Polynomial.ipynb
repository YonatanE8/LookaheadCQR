{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from LookaheadCQR.cqr_lookahead.uncertainty import CQR\n",
    "\n",
    "\n",
    "from LookaheadCQR.lookahead.models.lookahead import Lookahead\n",
    "import LookaheadCQR.lookahead.models.uncertainty as uncert\n",
    "import LookaheadCQR.lookahead.models.prediction as pred\n",
    "import LookaheadCQR.lookahead.models.propensity as prop\n",
    "from LookaheadCQR.lookahead.models.models import polyRegression\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the data hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Random Seed\n",
    "seed = 3\n",
    "\n",
    "# Coefficients of the ground truth polynomial\n",
    "# coeffs[i] denotes the coefficient of x^i th term\n",
    "coeffs = [0.1, 0.5, -0.8]\n",
    "\n",
    "# Number of Training Samples\n",
    "n = 1000\n",
    "\n",
    "# Our input is drawn from the normal distribution\n",
    "# with std = sig and mean = offset\n",
    "sig = 0.5\n",
    "offset = -0.8\n",
    "\n",
    "# std of noise added to the data\n",
    "ns = 0.1\n",
    "\n",
    "# Split ratio for train-test\n",
    "trn_sz = 0.75\n",
    "\n",
    "# Degree of polynomial regressor\n",
    "degree = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the ground truth function f*\n",
    "\n",
    "f1*(x) =  -0.8 x<sup>2</sup> + 0.5 x + 0.1\n",
    "\n",
    "f2*(x) =  -0.8 sin(x) + 0.5 sin(x / 2) + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Fstar_parabola():\n",
    "    def __init__(self, coeffs = []):\n",
    "        self.coeffs = coeffs\n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    def predict(self, x):\n",
    "        c = self.coeffs[-1]\n",
    "        for i in range(2, len(self.coeffs) + 1):\n",
    "            c = self.coeffs[-i] + c*x\n",
    "        return c.flatten()\n",
    "\n",
    "class Fstar_sin():\n",
    "    def __init__(self, coeffs = []):\n",
    "        self.coeffs = coeffs\n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    def predict(self, x):\n",
    "        c = self.coeffs[-1]\n",
    "        for i in range(2, len(self.coeffs) + 1):\n",
    "            c = self.coeffs[-i] + c*np.sin(x / (i - 1))\n",
    "        return c.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# Pick an f* function\n",
    "fstar = Fstar_parabola(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 1000 , n_trn: 750 , n_tst: 250\n"
     ]
    }
   ],
   "source": [
    "x = np.random.normal(size = (n, 1), scale = sig) + offset\n",
    "y = fstar.predict(x)\n",
    "y += np.random.normal(scale = ns, size = y.shape)\n",
    "\n",
    "n, d = x.shape\n",
    "x_trn, x_tst, y_trn, y_tst = train_test_split(x, y, test_size = 1 - trn_sz, random_state=seed)\n",
    "n_trn, n_tst = (x_trn.shape[0], x_tst.shape[0])\n",
    "print(\"n:\", n, \", n_trn:\", n_trn, \", n_tst:\", n_tst)\n",
    "xs = [x_trn, x_tst, x]\n",
    "ys = [y_trn, y_tst, y]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the model hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: [1.]\n"
     ]
    }
   ],
   "source": [
    "# l1/l2 Regularization coefficient\n",
    "alpha = 0.\n",
    "# Lam controls the tradeoff between accuracy and decision improvement\n",
    "lam = 4.\n",
    "\n",
    "\" Hyperparamteres for Lookahead\"\n",
    "# Decision step size\n",
    "eta = 0.8\n",
    "# Number of cycles for training\n",
    "num_cycles = 10\n",
    "# Z-score controls size of confidence intervas\n",
    "z_score = 1.65 # for confiednce intervals (1.28-90%, 1.65=95%)\n",
    "\n",
    "\"\"\" Hyperparameters for Prediction Model\"\"\"\n",
    "# Learning rate\n",
    "lr_f = 0.05\n",
    "# Number of training iterations\n",
    "num_iter_init = 1000\n",
    "num_iter_f = 100\n",
    "num_iter_base = num_iter_init + num_iter_f*num_cycles\n",
    "\n",
    "\"\"\" Hyperparameters for Uncertanity Model\"\"\"\n",
    "#number of bootstrapped models\n",
    "num_gs = 10\n",
    "# Learning rate\n",
    "lr_g = 0.001\n",
    "# Number of training iterations\n",
    "num_iter_g = 5000 #for training g in cycles\n",
    "\n",
    "\"\"\" Mask\"\"\"\n",
    "# mask[i] is 1 if it can be changed for making decisions\n",
    "mask = np.ones(d)\n",
    "print('mask:', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions to print performance\n",
    "def get_perf(model, xs, ys, eta, mask, uncert=False):\n",
    "    perf = {'mse':[], 'mae':[], 'improve':[], 'imprate':[], 'contain':[], 'size':[]}\n",
    "    perf['mse'].append([model.mse(x_,y_) for x_,y_ in zip(xs,ys)])\n",
    "    perf['mae'].append([model.mae(x_,y_) for x_,y_ in zip(xs,ys)])\n",
    "    perf['improve'].append([model.improve(x_,y_,eta,mask) for x_,y_ in zip(xs,ys)])\n",
    "    perf['imprate'].append([model.improve_rate(x_,y_,eta,mask) for x_,y_ in zip(xs,ys)])\n",
    "    if uncert:\n",
    "        xsp = [model.move_points(x_) for x_ in xs]\n",
    "        perf['contain'].append([model.contain(x_)[0] for x_ in [*xsp, x]])\n",
    "        perf['size'].append([model.contain(x_)[1] for x_ in [*xsp, x]])\n",
    "    perf = {k:np.asarray(v) for k,v in zip(perf.keys(),perf.values())}\n",
    "    return perf\n",
    "\n",
    "def print_perf(perf, idx=0, uncert=False):\n",
    "    print('\\ttrn\\ttst\\tall')\n",
    "    print(('mse'+'\\t{:.4f}'*3).format(*perf['mse'][idx,:]))\n",
    "    print(('mae'+'\\t{:.4f}'*3).format(*perf['mae'][idx,:]))\n",
    "    print(('imprv'+'\\t{:.4f}'*3).format(*perf['improve'][idx,:]))\n",
    "    print(('imprt'+'\\t{:.4f}'*3).format(*perf['imprate'][idx,:]))\n",
    "    print()\n",
    "    if uncert:\n",
    "        print('\\ttrn\\'\\ttst\\'\\tall')\n",
    "        print(('contn'+'\\t{:.3f}'*3).format(*perf['contain'][idx,:]))\n",
    "        print(('intrsz'+'\\t{:.3f}'*3).format(*perf['size'][idx,:]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the baseline model with no lookahead regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline:\n",
      "t: 0\n",
      "[f] mse: 0.0105, la_reg: 0.0000, norm_reg: 0.0000, obj: 0.0105\n",
      "[f] improve*: 1.086\n",
      "\n",
      "\ttrn\ttst\tall\n",
      "mse\t0.0105\t0.0093\t0.0102\n",
      "mae\t0.0823\t0.0765\t0.0808\n",
      "imprv\t1.0863\t1.1010\t1.0900\n",
      "imprt\t0.9707\t0.9760\t0.9720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train baseline\n",
    "verbose = True\n",
    "\n",
    "print('training baseline:')\n",
    "f_model = polyRegression(1, 1, degree)\n",
    "f_base = pred.PredModel(d, model=f_model, reg_type='none', alpha=alpha, lr=lr_f, num_iter_init=num_iter_base)\n",
    "model_base = Lookahead(f_base, None, None, lam=0., eta=eta, mask=mask, ground_truth_model=fstar)\n",
    "_, _ = model_base.train(x_trn, y_trn, num_cycles=0, random_state=seed, verbose=verbose)\n",
    "\n",
    "perf_base = get_perf(model_base, xs, ys, eta, mask)\n",
    "print_perf(perf_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the paper's lookahead model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lookahead:\n",
      "t: 0\n",
      "[f] mse: 0.0108, la_reg: 0.0000, norm_reg: 0.0000, obj: 0.0108\n",
      "[f] improve*: 1.091\n",
      "\n",
      "t: 1\n",
      "[h] n_eff: 1.43, w_sum: 3110.46\n",
      "[u] loss: 0.0031, norm_reg: 0.0000, obj: 0.0031\n",
      "[u] size: 0.563, contain*: 1.000\n",
      "[f] mse: 0.0339, la_reg: 0.0661, norm_reg: 0.0000, obj: 0.2984\n",
      "[f] improve*: 0.956\n",
      "\n",
      "t: 2\n",
      "[h] n_eff: 1.55, w_sum: 452.80\n",
      "[u] loss: 0.0040, norm_reg: 0.0000, obj: 0.0040\n",
      "[u] size: 0.491, contain*: 1.000\n",
      "[f] mse: 0.0419, la_reg: 0.0565, norm_reg: 0.0000, obj: 0.2680\n",
      "[f] improve*: 0.950\n",
      "\n",
      "t: 3\n",
      "[h] n_eff: 1.55, w_sum: 542.11\n",
      "[u] loss: 0.0040, norm_reg: 0.0000, obj: 0.0040\n",
      "[u] size: 0.492, contain*: 0.989\n",
      "[f] mse: 0.0488, la_reg: 0.0523, norm_reg: 0.0000, obj: 0.2579\n",
      "[f] improve*: 0.941\n",
      "\n",
      "t: 4\n",
      "[h] n_eff: 1.56, w_sum: 800.42\n",
      "[u] loss: 0.0041, norm_reg: 0.0000, obj: 0.0041\n",
      "[u] size: 0.496, contain*: 0.899\n",
      "[f] mse: 0.0547, la_reg: 0.0495, norm_reg: 0.0000, obj: 0.2529\n",
      "[f] improve*: 0.930\n",
      "\n",
      "t: 5\n",
      "[h] n_eff: 1.58, w_sum: 1032.03\n",
      "[u] loss: 0.0042, norm_reg: 0.0000, obj: 0.0042\n",
      "[u] size: 0.498, contain*: 0.843\n",
      "[f] mse: 0.0592, la_reg: 0.0476, norm_reg: 0.0000, obj: 0.2496\n",
      "[f] improve*: 0.920\n",
      "\n",
      "t: 6\n",
      "[h] n_eff: 1.62, w_sum: 1184.85\n",
      "[u] loss: 0.0045, norm_reg: 0.0000, obj: 0.0045\n",
      "[u] size: 0.501, contain*: 0.809\n",
      "[f] mse: 0.0625, la_reg: 0.0462, norm_reg: 0.0000, obj: 0.2472\n",
      "[f] improve*: 0.913\n",
      "\n",
      "t: 7\n",
      "[h] n_eff: 1.65, w_sum: 1263.96\n",
      "[u] loss: 0.0047, norm_reg: 0.0000, obj: 0.0047\n",
      "[u] size: 0.502, contain*: 0.780\n",
      "[f] mse: 0.0645, la_reg: 0.0453, norm_reg: 0.0000, obj: 0.2457\n",
      "[f] improve*: 0.909\n",
      "\n",
      "t: 8\n",
      "[h] n_eff: 1.67, w_sum: 1314.19\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yonatane/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-8e26d5aadf90>\", line 12, in <module>\n",
      "    _, _ = model.train(x_trn, y_trn, num_cycles=num_cycles, random_state=seed, verbose=verbose)\n",
      "  File \"/home/yonatane/LookaheadCQR/LookaheadCQR/lookahead/models/lookahead.py\", line 74, in train\n",
      "    metrics_u_t = self.u.fit(x, y, w, random_state=random_state)\n",
      "  File \"/home/yonatane/LookaheadCQR/LookaheadCQR/lookahead/models/uncertainty.py\", line 106, in fit\n",
      "    objective.backward()\n",
      "  File \"/home/yonatane/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/torch/_tensor.py\", line 255, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/home/yonatane/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 147, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yonatane/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yonatane/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/yonatane/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/yonatane/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/yonatane/Anaconda38/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/yonatane/Anaconda38/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/yonatane/Anaconda38/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/yonatane/Anaconda38/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/yonatane/Anaconda38/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/yonatane/Anaconda38/lib/python3.8/posixpath.py\", line 424, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/home/yonatane/Anaconda38/lib/python3.8/posixpath.py\", line 82, in join\n",
      "    for b in map(os.fspath, p):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m<ipython-input-9-8e26d5aadf90>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLookahead\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mu\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mh\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlam\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlam\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meta\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0meta\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mground_truth_model\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfstar\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_trn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_trn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_cycles\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_cycles\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/LookaheadCQR/LookaheadCQR/lookahead/models/lookahead.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, x, y, num_cycles, init, random_state, verbose)\u001B[0m\n\u001B[1;32m     73\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 74\u001B[0;31m                 \u001B[0mmetrics_u_t\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mu\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     75\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/LookaheadCQR/LookaheadCQR/lookahead/models/uncertainty.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, w, force_all, random_state)\u001B[0m\n\u001B[1;32m    105\u001B[0m                 \u001B[0mobjective\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malpha\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0ml2_reg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 106\u001B[0;31m                 \u001B[0mobjective\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    107\u001B[0m                 \u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/torch/_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    254\u001B[0m                 inputs=inputs)\n\u001B[0;32m--> 255\u001B[0;31m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    256\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/torch/autograd/__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 147\u001B[0;31m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[1;32m    148\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m~/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2060\u001B[0m                         \u001B[0;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2061\u001B[0;31m                         \u001B[0mstb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2062\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[0;32m~/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[1;32m   2061\u001B[0m                         \u001B[0mstb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2062\u001B[0m                     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2063\u001B[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[0m\u001B[1;32m   2064\u001B[0m                                             value, tb, tb_offset=tb_offset)\n\u001B[1;32m   2065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1365\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1367\u001B[0;31m         return FormattedTB.structured_traceback(\n\u001B[0m\u001B[1;32m   1368\u001B[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[1;32m   1369\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1265\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose_modes\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1266\u001B[0m             \u001B[0;31m# Verbose modes need a full traceback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1267\u001B[0;31m             return VerboseTB.structured_traceback(\n\u001B[0m\u001B[1;32m   1268\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1269\u001B[0m             )\n",
      "\u001B[0;32m~/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[1;32m   1122\u001B[0m         \u001B[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1123\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1124\u001B[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[0m\u001B[1;32m   1125\u001B[0m                                                                tb_offset)\n\u001B[1;32m   1126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[1;32m   1080\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1081\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1082\u001B[0;31m         \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1083\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1084\u001B[0m         \u001B[0mframes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Anaconda38/envs/LookaheadCQR/lib/python3.8/site-packages/IPython/core/ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[0;34m(etype, value, records)\u001B[0m\n\u001B[1;32m    380\u001B[0m     \u001B[0;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    381\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0metype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 382\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    383\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    384\u001B[0m     \u001B[0;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# train our model\n",
    "verbose = True\n",
    "\n",
    "print('Training lookahead:')\n",
    "f_model = polyRegression(1, 1, degree)\n",
    "g_model = polyRegression(1, 1, degree)\n",
    "\n",
    "f = pred.PredModel(d, model = f_model, reg_type='none', alpha=0., lr=lr_f, num_iter=num_iter_f, num_iter_init=num_iter_init)\n",
    "u = uncert.Bootstrap(d, model = g_model, alpha=0., num_gs=num_gs, z_score=z_score, lr=lr_g, num_iter=num_iter_g)\n",
    "h = prop.PropModel(random_state=seed)\n",
    "model = Lookahead(f, u, h, lam=lam, eta=eta, mask=mask, ground_truth_model=fstar)\n",
    "_, _ = model.train(x_trn, y_trn, num_cycles=num_cycles, random_state=seed, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our CQR + lookahead model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train our model\n",
    "verbose = True\n",
    "\n",
    "print('Training lookahead:')\n",
    "f_model = polyRegression(1, 1, degree)\n",
    "\n",
    "f = pred.PredModel(d, model = f_model, reg_type='none', alpha=0., lr=lr_f, num_iter=num_iter_f, num_iter_init=num_iter_init)\n",
    "u = CQR(d, tau=(0.05, 0.95), lr=lr_g, num_iter=num_iter_g)\n",
    "h = prop.PropModel(random_state=seed)\n",
    "nn_cqr_model = Lookahead(f, u, h, lam=lam, eta=eta, mask=mask, ground_truth_model=fstar)\n",
    "_, _ = nn_cqr_model.train(x_trn, y_trn, num_cycles=num_cycles, random_state=seed, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the performance of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "perf_base = get_perf(model_base, xs, ys, eta, mask)\n",
    "perf_la = get_perf(model, xs, ys, eta, mask, uncert=True)\n",
    "perf_la_cqr = get_perf(nn_cqr_model, xs, ys, eta, mask, uncert=True)\n",
    "\n",
    "print('\\nBaseline Model:')\n",
    "print_perf(perf_base)\n",
    "print('Lookahead Model:')\n",
    "print_perf(perf_la, uncert=True)\n",
    "print('Lookahead+CQR Model:')\n",
    "print_perf(perf_la_cqr, uncert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results\n",
    "The main plot shows the predictions generated by the lookahead model.  The inlay plot shows the performance of the baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function for plotting\n",
    "def plot_quad(ax, M, x, y, x_plot, y_plot, eta, mask, color, lw=1, osz=50, olw=1,\n",
    "              fill_between_color = 'g'):\n",
    "    x_plot_th = torch.from_numpy(x_plot.astype(np.float32))\n",
    "    ax.plot(x_plot, y_plot, '--', color=\"tab:orange\", linewidth =1.0, label =\"gt\", alpha=0.6)\n",
    "\n",
    "    f_pred = M.f.predict(x_plot)\n",
    "    ax.plot(x_plot, f_pred, label=\"f\", linewidth=lw, alpha=0.6)\n",
    "\n",
    "    if M.u is not None:\n",
    "        u_pred, l_pred = M.u.lu(x_plot_th)\n",
    "        u_pred = u_pred.detach().numpy()\n",
    "        l_pred = l_pred.detach().numpy()\n",
    "        ax.fill_between(x_plot.flatten(), u_pred.flatten(), l_pred.flatten(),\n",
    "                        color=fill_between_color, alpha=0.05, zorder=0)\n",
    "        ax.plot(x_plot.flatten(), u_pred.flatten(), f\"tab:{color}\", linewidth=1.0, alpha=0.5, zorder=0)\n",
    "        ax.plot(x_plot.flatten(), l_pred.flatten(), f\"tab:{color}\", linewidth=1.0, alpha=0.5, zorder=0)\n",
    "\n",
    "    xp = M.move_points(x, eta, mask)\n",
    "    ypstar = M.fstar.predict(xp)\n",
    "    ax.scatter(x, y, color=\"white\", edgecolor=\"tab:blue\", alpha = 1, s=osz, zorder=10, linewidth=olw)\n",
    "    ax.scatter(xp, ypstar, color=\"white\", edgecolor=\"tab:red\", alpha = 1, s=osz, zorder=10, linewidth=olw)\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (6.0, 4.5)\n",
    "x_plot = np.linspace(-3.0, 3.0, 1000)[:, np.newaxis]\n",
    "y_plot = fstar.predict(x_plot)\n",
    "\n",
    "ax = plt.axes()\n",
    "axins = inset_axes(ax, width=\"40%\", height=\"40%\", loc=4)\n",
    "plot_quad(axins, model_base, x, y, x_plot, y_plot, eta, mask, osz=10, olw=0.5,\n",
    "          color='green')\n",
    "axins.set_xlim([-2, 3.3])\n",
    "axins.set_ylim([-7, 1.0])\n",
    "\n",
    "plot_quad(ax, model, x, y, x_plot, y_plot, eta, mask, lw=2, color='green')\n",
    "ax.set_xlim([-2.2, 2.2])\n",
    "ax.set_ylim([-4, 1])\n",
    "plt.title(r'$\\eta={}$'.format(eta))\n",
    "\n",
    "plot_quad(ax, nn_cqr_model, x, y, x_plot, y_plot, eta, mask, lw=2, color='purple',\n",
    "          fill_between_color='m')\n",
    "ax.set_xlim([-2.2, 2.2])\n",
    "ax.set_ylim([-4, 1])\n",
    "plt.title(r'$\\eta={}$'.format(eta))\n",
    "\n",
    "ax.legend(\n",
    "    [\n",
    "        r'$f^*$',\n",
    "        r'$f$',\n",
    "        r'$Lookahead$',\n",
    "        r'$Lookahead + CQR$',\n",
    "        r'$(x,y)$',\n",
    "        r\"$(x',y')$\"\n",
    "    ],\n",
    "    fontsize=8,\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}